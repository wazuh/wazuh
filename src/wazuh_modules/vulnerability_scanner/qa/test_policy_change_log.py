import json
import platform
import subprocess
import socket
import os
import time
import threading
from pathlib import Path
import glob

import pytest
from jsonschema import validate
from jsonschema.exceptions import ValidationError

import logging

LOGGER = logging.getLogger(__name__)
import re
import time

def find_regex_in_file(regex, file, times=1, max_timeout=50):
    pattern = re.compile(regex)
    start_time = time.time()

    while time.time() - start_time < max_timeout:
        count = 0
        with open(file, 'r') as f:
            content = f.read()
            count = len(pattern.findall(content))
            LOGGER.debug(f"Found {count} matches")
            if count == times:
                return True

        time.sleep(1)
    return False

def tail_log(file, expected_lines, found_lines, timeout):
    start_time = time.time()
    with open(file, "r") as f:
        while not all(found_lines.values()) and (time.time() - start_time <= timeout):
            line = f.readline()
            if not line:
                continue
            # Check if the line contains the expected output
            for expected in expected_lines:
                if expected in line and not found_lines[expected]:
                    LOGGER.debug(f"Found line: {line}")
                    found_lines[expected] = True

@pytest.fixture
def run_on_end(request):
    yield
    # Read the location of the log
    if 'GITHUB_WORKSPACE' not in os.environ:
        LOGGER.info("GITHUB_WORKSPACE is not defined")
        return
    path = os.environ['GITHUB_WORKSPACE']
    # Search for the log.out file in path variable
    for file_path in glob.glob(f'{path}/**/log.out', recursive=True):
        # Copy the file found to another directory
        LOGGER.info(f"Copying {file_path} to {path}/qa_logs/log.out.{request.node.name}")
        os.system(f"cp {file_path} {path}/qa_logs/log.out.{request.node.name}")

@pytest.fixture
def runner_function(request, run_on_end):
    # Delete previous inventory directory if exists
    if Path("queue/vd/inventory").exists():
        for file in Path("queue/vd/inventory").glob("*"):
            file.unlink()
        Path("queue/vd/inventory").rmdir()

    if Path("queue/indexer/wazuh-states-vulnerabilities").exists():
        for file in Path("queue/indexer/wazuh-states-vulnerabilities").glob("*"):
            file.unlink()
        Path("queue/indexer/wazuh-states-vulnerabilities").rmdir()

    if Path("queue/vd/event").exists():
        for file in Path("queue/vd/event").glob("*"):
            file.unlink()
        Path("queue/vd/event").rmdir()

    # Set the path to the binary
    cmd = Path("build/wazuh_modules/vulnerability_scanner/testtool/scanner/", "vd_scanner_testtool")
    cmdAlt = Path("wazuh_modules/vulnerability_scanner/build/testtool/scanner/", "vd_scanner_testtool")

    # Ensure the binary exists
    if not cmd.exists():
        cmd = cmdAlt
    assert cmd.exists(), "The binary does not exists"

    # Remove previous log file if exists
    if Path("log.out").exists():
        Path("log.out").unlink()

    test_folder = request.param
    LOGGER.debug(f"Running test {test_folder}")

    json_files = sorted(Path(test_folder).glob("args_*.json"))
    for json_file in json_files:
        LOGGER.debug(f"Running test {json_file}")

        # Read arguments from the json file
        with open(json_file) as f:
            args = json.load(f)

        command = [cmd] + args

        process = subprocess.Popen(command)

        # Check if the process is initialized finding in the log file the line "Vulnerability scanner module started"
        start_time = time.time()
        log_file = "log.out"

        while not Path(log_file).exists() and (time.time() - start_time <= 10):
            time.sleep(1)

        # Check if the log file exists, if the line is not found, try again in 1 second
        assert Path(log_file).exists(), "The log file does not exists"

        LOGGER.debug(f"Wating for the process to be initialized")
        found = find_regex_in_file(r"Vulnerability scanner module (started|is disabled)", log_file)
        assert found, "The process is not initialized"
        LOGGER.debug(f"Process initialized")

        # Regex to extract the value of the *** in args_***.json
        regex = r"args_(\d+).json"
        match = re.search(regex, json_file.name)
        assert match, "The regex does not match"
        expected_json_file = Path(test_folder, f"expected_{match.group(1)}.out")
        assert expected_json_file.exists(), "The expected file does not exists"

        expected_lines = []

        json_data = json.load(open(expected_json_file))
        LOGGER.debug(f"Expected json data: {json_data}")
        for line in json_data:
            expected_lines.append(line)

        LOGGER.debug(f"Expected lines: {expected_lines}")
        quantity_expected_lines = len(expected_lines)
        LOGGER.debug(f"Quantity expected lines: {quantity_expected_lines}")

        found_lines = {line: False for line in expected_lines}
        timeout = 10

        basetimeout = timeout
        for expected_line in expected_lines:
            while not found_lines[expected_line]:
                LOGGER.debug(f"Waiting for: {expected_line}")
                if timeout < 8*basetimeout:
                    tail_log(log_file, expected_lines, found_lines, timeout)
                    timeout = 1.5*timeout
                else:
                    LOGGER.error(f"Timeout waiting for: {expected_line}")
                    basetimeout = timeout
                    break

        # Wait for the process to finish, sigterm is sent to the process
        process.terminate()

        LOGGER.debug(f"Waiting for the process to finish")

    return found_lines

test_folders = sorted(Path("wazuh_modules/vulnerability_scanner/qa/test_data_policy").glob(os.getenv('WAZUH_VD_TEST_GLOB', '*')))

@pytest.mark.skip(reason="The test is disabled in this branch because some other developments must be backported first")
@pytest.mark.parametrize("runner_function", test_folders, indirect=True)
def test_configuration_change(runner_function):
    # change working directory to the root of the project parent directory
    # This is required to run the binary
    os.chdir(Path(__file__).parent.parent.parent.parent)

    found_lines = runner_function
    assert all(found_lines.values()), "The test is failed because the expected output is not found"
